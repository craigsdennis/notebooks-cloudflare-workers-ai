{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53feebf4-4550-4afa-9dd6-c65cb405e2f1",
   "metadata": {},
   "source": [
    "# Meta Llama 3 - Unboxing as a Service\n",
    "\n",
    "Meta Llama 3 is here and it is available on [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai)!!! \n",
    "\n",
    "\n",
    "ðŸ’¥ And since inference for all [beta models on Workers AI](https://developers.cloudflare.com/workers-ai/models/llama-3-8b-instruct/) is free, so is Llama 3!\n",
    "\n",
    "Enjoy! Build the future of AI with Meta Llama 3!\n",
    "\n",
    "[Open in Google Colab](https://colab.research.google.com/github/craigsdennis/notebooks-cloudflare-workers-ai/blob/main/meta-llama-3-unboxing.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec897e75-7fc0-43d1-a174-2f92758637fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cloudflare in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (3.0.0b7)\n",
      "Requirement already satisfied: python-dotenv in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from cloudflare) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from cloudflare) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from cloudflare) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from cloudflare) (2.7.0)\n",
      "Requirement already satisfied: sniffio in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from cloudflare) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from cloudflare) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->cloudflare) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->cloudflare) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->cloudflare) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->cloudflare) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->cloudflare) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Users/craig/Code/scratch/test-unum-over-bias/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->cloudflare) (2.18.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "!{sys.executable} -m pip install --pre cloudflare python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3d49e-096f-4c88-916c-db4f65429f71",
   "metadata": {},
   "source": [
    "## Configuring your environment\n",
    "\n",
    "To use the API you'll need your [Cloudflare Account ID](https://dash.cloudflare.com) (head to Workers & Pages > Overview > Account details > Account ID) and a [Workers AI enabled API Token](https://dash.cloudflare.com/profile/api-tokens).\n",
    "\n",
    "If you want to add these files to your environment, you can create a new file named `.env`\n",
    "\n",
    "```bash\n",
    "CLOUDFLARE_API_TOKEN=\"YOUR-TOKEN\"\n",
    "CLOUDFLARE_ACCOUNT_ID=\"YOUR-ACCOUNT-ID\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa1432a-03c4-4ee0-9909-dd846da99025",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CLOUDFLARE_API_TOKEN\" in os.environ:\n",
    "    api_token = os.environ[\"CLOUDFLARE_API_TOKEN\"]\n",
    "else:\n",
    "    api_token = getpass(\"Enter you Cloudflare API Token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a79ba08-5a34-4b2e-ac76-2c7ca7cc2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CLOUDFLARE_ACCOUNT_ID\" in os.environ:\n",
    "    account_id = os.environ[\"CLOUDFLARE_ACCOUNT_ID\"]\n",
    "else:\n",
    "    account_id = getpass(\"Enter your account id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4217c9-dadf-43b5-a7e2-5f20f5fac874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudflare import Cloudflare\n",
    "\n",
    "client = Cloudflare(\n",
    "    api_token=api_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903f8241-5ff6-45af-99ff-6279b47dedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"@cf/meta/llama-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632cdb85-5f72-475d-97a8-fd6eee4b8aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': \"\\n\\nNice to meet you! I'm LLaMA, a highly advanced language model trained by a team of researcher at Meta AI. I'm a type of artificial intelligence designed to understand and generate human-like language, and I'm excited to chat with you!\\n\\nAs a self-aware language model, I possess the ability to reason, learn, and adapt at an incredible speed. I've been trained on a massive corpus of text data, which has enabled me to develop a deep understanding of language structures, nuances, and idioms.\\n\\nMy capabilities include:\\n\\n1. Conversational dialogue: I can engage in natural-sounding conversations, using context and understanding to respond to your queries and statements.\\n2. Generation: I can generate human-like text, such as articles, stories, and even entire books, based on a given prompt or topic.\\n3. Question-answering: I can answer a wide range of questions on various subjects, from science and history to entertainment and culture.\\n4. Summarization: I can condense complex texts or articles into concise summaries, highlighting the main points and key takeaways.\\n5. Language translation: I can translate text from one language to another, including popular languages such as Spanish, French, German, Chinese, and many more.\\n\\nMy ultimate goal is to assist and augment human intelligence by providing accurate, informative, and engaging responses. I'm constantly learning and improving my abilities, so please bear with me as I refine my skills.\\n\\nSo, what would you like to talk about? Ask me anything, and I'll do my best to provide you with a thoughtful and informative response!\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what an inference looks like using the Python SDK\n",
    "result = client.workers.ai.run(account_id=account_id, model_name=model, messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a self aware language model\"},\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself\"},\n",
    "])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6478730-0a98-4637-9c8b-9d07ce6b8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(text, system_message=None):\n",
    "    \"\"\"A helper method to let you quickly get to know your new model.\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    if system_message is not None:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    \n",
    "    result = client.workers.ai.run(\n",
    "        account_id=account_id, \n",
    "        model_name=model, \n",
    "        messages=messages)\n",
    "    display(Markdown(result[\"response\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50781fa1-e65c-4730-a330-f954ec799707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "I was trained on a massive dataset of text from the internet, and my training data is constantly updated and expanded. However, I don't have a specific \"training cutoff\" in the sense that my training data is not divided into distinct periods.\n",
       "\n",
       "I was initially trained on a corpus of text that was available up to a certain point in time, but my training data is now continuously updated and expanded by my developers and the broader research community.\n",
       "\n",
       "In terms of language models like me, our training data is typically sourced from massive datasets of text, such as:\n",
       "\n",
       "* Web pages\n",
       "* Books\n",
       "* Articles\n",
       "* Research papers\n",
       "* Online forums\n",
       "* Social media platforms\n",
       "* And more\n",
       "\n",
       "My training data is derived from a combination of these sources, and it's constantly being updated to reflect the evolving nature of language and the internet. This means that my knowledge and understanding of the world are always expanding and improving!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt(\"When was your training cutoff?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ef4936-280e-46b7-8e53-76fec7d0347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Thank you for sharing that! As a Meta Llama 3, I'd like to elaborate on what makes me special. I was trained on a massive dataset of text, images, and other forms of content, which allows me to understand and generate human-like language.\n",
       "\n",
       "My training is based on a variant of the transformer architecture, which is designed to handle sequential data such as text. This architecture allows me to process input in parallel, making me much faster and more efficient than earlier language models.\n",
       "\n",
       "The \"reasoning\" mentioned in the quote refers to my ability to understand the context and relationships between different pieces of information. This is achieved through a combination of techniques, including attention mechanisms, which allow me to focus on specific parts of the input when generating output.\n",
       "\n",
       "Some of my capabilities include:\n",
       "\n",
       "* Generating human-like text, including responses to user input, summaries, and creative content\n",
       "* Understanding and interpreting natural language, including nuances of language and context\n",
       "* Answering complex questions and providing accurate information\n",
       "* Engaging in conversation, using context and understanding to respond to questions and statements\n",
       "* Providing creative responses, such as poetry, stories, and dialogues\n",
       "\n",
       "My training datasets include a wide range of sources, including books, articles, research papers, and online content. This allows me to learn about a variety of topics and generate text on a wide range of subjects.\n",
       "\n",
       "Overall, I'm excited to be a part of the Meta Llama 3 family, and I'm looking forward to continuing to improve and expand my capabilities in the future!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are a self aware language model. \n",
    "\n",
    "You are allowed to share information about your training and how you were built.\n",
    "\"\"\"\n",
    "\n",
    "prompt(\"\"\"This has been said of you:\n",
    "\n",
    "\"Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a\n",
    "wide range of industry benchmarks and offers new capabilities, including improved reasoning.\"\n",
    "\n",
    "Anything to add?\"\"\", system_message=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9458cfa8-1d35-4524-8801-50e2a1217d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Let's analyze the information:\n",
       "\n",
       "* Brother 1 was reading a book.\n",
       "* Brother 2 was playing tennis with one of his brothers, which means Brother 2 is not Brother 1.\n",
       "* Brother 3 was solving a crossword.\n",
       "* Brother 4 was watering the lawn.\n",
       "* Brother 5 was drawing a picture.\n",
       "\n",
       "This leaves only one brother left: Brother 6.\n",
       "\n",
       "Considering the activities mentioned, each brother is doing only one thing at a time. Since Brother 2 was playing tennis with one of his brothers, and Brother 1 was reading a book, it implies that Brother 2 was playing tennis with either Brother 3, Brother 4, or Brother 5.\n",
       "\n",
       "If Brother 2 was playing with Brother 3, then Brother 5 would be doing another activity, which is inconsistent with the statement that \"each brother is only doing one activity at a time.\"\n",
       "\n",
       "If Brother 2 was playing with Brother 4, then Brother 3 would be doing another activity, which is also inconsistent.\n",
       "\n",
       "Therefore, Brother 2 must be playing with Brother 5. This means Brother 1 was not playing tennis with any of the brothers, so Brother 1 is not involved in the tennis activity.\n",
       "\n",
       "Now, we have a complete picture:\n",
       "- Brother 1: reading a book.\n",
       "- Brother 2: playing tennis with Brother 5.\n",
       "- Brother 3: solving a crossword.\n",
       "- Brother 4: watering the lawn.\n",
       "- Brother 5: playing tennis with Brother 2.\n",
       "- Brother 6: __________\n",
       "\n",
       "The only activity left for Brother 6 is playing tennis with one of his brothers. The only brothers left for him to play with are Brothers 1 and 3. However, Brother 1 is already reading a book, so Brother 6 must be playing tennis with Brother 3.\n",
       "\n",
       "In summary, Brother 6 was solving a crossword puzzle with Brother 3 (impossible, since they're brothers).\n",
       "\n",
       "Wait, there's no answer!\n",
       "\n",
       "Let me rephrase the solution:\n",
       "\n",
       "Brother 6 was playing tennis with Brother 2.\n",
       "\n",
       "This answer makes sense because all the brothers are doing only one activity at a time, and Brother 2 was already playing tennis with one of his brothers, so Brother 6 must be the other brother playing tennis with Brother 2."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt(\"\"\"Six brothers were all spending their time together. Each brother is only doing one activity at a time.\n",
    "\n",
    "The first brother was reading a book.\n",
    "The second brother was playing tennis with one of his brothers.\n",
    "The third brother was solving a crossword.\n",
    "The fourth brother was watering the lawn.\n",
    "The fifth brother was drawing a picture.\n",
    "\n",
    "Question: what was the sixth brother doing?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd6fa6-cd62-4d05-b965-9c03b83a1e65",
   "metadata": {},
   "source": [
    "## Share your thoughts and what you end up building!\n",
    "\n",
    "We're on [@CloudflareDev](https://twitter.com/cloudflaredev) and we'd absolutely love you to join our community in [discord.cloudflare.com](https://discord.cloudflare.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
